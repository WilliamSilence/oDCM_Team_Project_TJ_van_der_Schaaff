{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1CnFaonEHOP"
   },
   "source": [
    "# **oDCM Resit:** Python Code Script $-$ _Scraping AliExpress: Unveiling Market Trends in Consumer Electronics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkXO3kcuXAaJ"
   },
   "source": [
    "## Step 1: Install Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEnEHGvkVOvF",
    "outputId": "c93ae40a-3974-48be-eb68-82804d85b0f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-30 16:34:40--  https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chrome-linux64.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.207, 142.251.162.207, 74.125.134.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149157879 (142M) [application/zip]\n",
      "Saving to: ‘chrome-linux64.zip’\n",
      "\n",
      "chrome-linux64.zip  100%[===================>] 142.25M   141MB/s    in 1.0s    \n",
      "\n",
      "2024-04-30 16:34:41 (141 MB/s) - ‘chrome-linux64.zip’ saved [149157879/149157879]\n",
      "\n",
      "Archive:  chrome-linux64.zip\n",
      "  inflating: chrome-linux64/ABOUT    \n",
      "  inflating: chrome-linux64/MEIPreload/manifest.json  \n",
      "  inflating: chrome-linux64/MEIPreload/preloaded_data.pb  \n",
      "  inflating: chrome-linux64/chrome   \n",
      "  inflating: chrome-linux64/chrome-wrapper  \n",
      "  inflating: chrome-linux64/chrome_100_percent.pak  \n",
      "  inflating: chrome-linux64/chrome_200_percent.pak  \n",
      "  inflating: chrome-linux64/chrome_crashpad_handler  \n",
      "  inflating: chrome-linux64/chrome_sandbox  \n",
      "  inflating: chrome-linux64/icudtl.dat  \n",
      "  inflating: chrome-linux64/libEGL.so  \n",
      "  inflating: chrome-linux64/libGLESv2.so  \n",
      "  inflating: chrome-linux64/libvk_swiftshader.so  \n",
      "  inflating: chrome-linux64/libvulkan.so.1  \n",
      " extracting: chrome-linux64/product_logo_48.png  \n",
      "  inflating: chrome-linux64/resources.pak  \n",
      "  inflating: chrome-linux64/v8_context_snapshot.bin  \n",
      "  inflating: chrome-linux64/vk_swiftshader_icd.json  \n",
      "  inflating: chrome-linux64/xdg-mime  \n",
      "  inflating: chrome-linux64/xdg-settings  \n",
      "   creating: chrome-linux64/locales/\n",
      "  inflating: chrome-linux64/locales/af.pak.info  \n",
      "  inflating: chrome-linux64/locales/ja.pak  \n",
      "  inflating: chrome-linux64/locales/fil.pak  \n",
      "  inflating: chrome-linux64/locales/ca.pak.info  \n",
      "  inflating: chrome-linux64/locales/es.pak.info  \n",
      "  inflating: chrome-linux64/locales/th.pak  \n",
      "  inflating: chrome-linux64/locales/en-GB.pak.info  \n",
      "  inflating: chrome-linux64/locales/ro.pak  \n",
      "  inflating: chrome-linux64/locales/fil.pak.info  \n",
      "  inflating: chrome-linux64/locales/en-US.pak.info  \n",
      "  inflating: chrome-linux64/locales/hi.pak.info  \n",
      "  inflating: chrome-linux64/locales/sw.pak.info  \n",
      "  inflating: chrome-linux64/locales/lv.pak.info  \n",
      "  inflating: chrome-linux64/locales/sw.pak  \n",
      "  inflating: chrome-linux64/locales/uk.pak  \n",
      "  inflating: chrome-linux64/locales/de.pak.info  \n",
      "  inflating: chrome-linux64/locales/sv.pak.info  \n",
      "  inflating: chrome-linux64/locales/et.pak.info  \n",
      "  inflating: chrome-linux64/locales/ko.pak  \n",
      "  inflating: chrome-linux64/locales/zh-CN.pak  \n",
      "  inflating: chrome-linux64/locales/bg.pak  \n",
      "  inflating: chrome-linux64/locales/sl.pak.info  \n",
      "  inflating: chrome-linux64/locales/id.pak.info  \n",
      "  inflating: chrome-linux64/locales/pl.pak.info  \n",
      "  inflating: chrome-linux64/locales/ru.pak.info  \n",
      "  inflating: chrome-linux64/locales/it.pak.info  \n",
      "  inflating: chrome-linux64/locales/ko.pak.info  \n",
      "  inflating: chrome-linux64/locales/mr.pak.info  \n",
      "  inflating: chrome-linux64/locales/mr.pak  \n",
      "  inflating: chrome-linux64/locales/es.pak  \n",
      "  inflating: chrome-linux64/locales/cs.pak.info  \n",
      "  inflating: chrome-linux64/locales/hr.pak.info  \n",
      "  inflating: chrome-linux64/locales/cs.pak  \n",
      "  inflating: chrome-linux64/locales/lt.pak  \n",
      "  inflating: chrome-linux64/locales/ml.pak.info  \n",
      "  inflating: chrome-linux64/locales/te.pak  \n",
      "  inflating: chrome-linux64/locales/ta.pak.info  \n",
      "  inflating: chrome-linux64/locales/ca.pak  \n",
      "  inflating: chrome-linux64/locales/gu.pak  \n",
      "  inflating: chrome-linux64/locales/ar.pak  \n",
      "  inflating: chrome-linux64/locales/ms.pak  \n",
      "  inflating: chrome-linux64/locales/uk.pak.info  \n",
      "  inflating: chrome-linux64/locales/da.pak  \n",
      "  inflating: chrome-linux64/locales/nb.pak.info  \n",
      "  inflating: chrome-linux64/locales/am.pak.info  \n",
      "  inflating: chrome-linux64/locales/ml.pak  \n",
      "  inflating: chrome-linux64/locales/ro.pak.info  \n",
      "  inflating: chrome-linux64/locales/ur.pak.info  \n",
      "  inflating: chrome-linux64/locales/sk.pak  \n",
      "  inflating: chrome-linux64/locales/es-419.pak  \n",
      "  inflating: chrome-linux64/locales/th.pak.info  \n",
      "  inflating: chrome-linux64/locales/en-GB.pak  \n",
      "  inflating: chrome-linux64/locales/he.pak  \n",
      "  inflating: chrome-linux64/locales/ta.pak  \n",
      "  inflating: chrome-linux64/locales/hu.pak.info  \n",
      "  inflating: chrome-linux64/locales/lt.pak.info  \n",
      "  inflating: chrome-linux64/locales/te.pak.info  \n",
      "  inflating: chrome-linux64/locales/et.pak  \n",
      "  inflating: chrome-linux64/locales/zh-TW.pak.info  \n",
      "  inflating: chrome-linux64/locales/af.pak  \n",
      "  inflating: chrome-linux64/locales/zh-TW.pak  \n",
      "  inflating: chrome-linux64/locales/zh-CN.pak.info  \n",
      "  inflating: chrome-linux64/locales/id.pak  \n",
      "  inflating: chrome-linux64/locales/hi.pak  \n",
      "  inflating: chrome-linux64/locales/ja.pak.info  \n",
      "  inflating: chrome-linux64/locales/kn.pak  \n",
      "  inflating: chrome-linux64/locales/bn.pak  \n",
      "  inflating: chrome-linux64/locales/el.pak  \n",
      "  inflating: chrome-linux64/locales/en-US.pak  \n",
      "  inflating: chrome-linux64/locales/el.pak.info  \n",
      "  inflating: chrome-linux64/locales/sr.pak  \n",
      "  inflating: chrome-linux64/locales/fr.pak  \n",
      "  inflating: chrome-linux64/locales/ar.pak.info  \n",
      "  inflating: chrome-linux64/locales/de.pak  \n",
      "  inflating: chrome-linux64/locales/vi.pak  \n",
      "  inflating: chrome-linux64/locales/pt-BR.pak  \n",
      "  inflating: chrome-linux64/locales/hu.pak  \n",
      "  inflating: chrome-linux64/locales/nl.pak.info  \n",
      "  inflating: chrome-linux64/locales/bg.pak.info  \n",
      "  inflating: chrome-linux64/locales/gu.pak.info  \n",
      "  inflating: chrome-linux64/locales/bn.pak.info  \n",
      "  inflating: chrome-linux64/locales/pt-PT.pak.info  \n",
      "  inflating: chrome-linux64/locales/kn.pak.info  \n",
      "  inflating: chrome-linux64/locales/hr.pak  \n",
      "  inflating: chrome-linux64/locales/fi.pak.info  \n",
      "  inflating: chrome-linux64/locales/pt-PT.pak  \n",
      "  inflating: chrome-linux64/locales/ms.pak.info  \n",
      "  inflating: chrome-linux64/locales/ur.pak  \n",
      "  inflating: chrome-linux64/locales/it.pak  \n",
      "  inflating: chrome-linux64/locales/fr.pak.info  \n",
      "  inflating: chrome-linux64/locales/pl.pak  \n",
      "  inflating: chrome-linux64/locales/es-419.pak.info  \n",
      "  inflating: chrome-linux64/locales/sr.pak.info  \n",
      "  inflating: chrome-linux64/locales/fa.pak.info  \n",
      "  inflating: chrome-linux64/locales/tr.pak  \n",
      "  inflating: chrome-linux64/locales/pt-BR.pak.info  \n",
      "  inflating: chrome-linux64/locales/fa.pak  \n",
      "  inflating: chrome-linux64/locales/vi.pak.info  \n",
      "  inflating: chrome-linux64/locales/he.pak.info  \n",
      "  inflating: chrome-linux64/locales/nb.pak  \n",
      "  inflating: chrome-linux64/locales/lv.pak  \n",
      "  inflating: chrome-linux64/locales/nl.pak  \n",
      "  inflating: chrome-linux64/locales/fi.pak  \n",
      "  inflating: chrome-linux64/locales/ru.pak  \n",
      "  inflating: chrome-linux64/locales/da.pak.info  \n",
      "  inflating: chrome-linux64/locales/tr.pak.info  \n",
      "  inflating: chrome-linux64/locales/sk.pak.info  \n",
      "  inflating: chrome-linux64/locales/sl.pak  \n",
      "  inflating: chrome-linux64/locales/am.pak  \n",
      "  inflating: chrome-linux64/locales/sv.pak  \n",
      "   creating: chrome-linux64/resources/\n",
      "   creating: chrome-linux64/resources/inspector_overlay/\n",
      "  inflating: chrome-linux64/resources/inspector_overlay/main.js  \n",
      "  inflating: chrome-linux64/resources/inspector_overlay/inspector_overlay_resources.grd  \n",
      "--2024-04-30 16:34:47--  https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chromedriver-linux64.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.207, 142.251.162.207, 74.125.134.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8597995 (8.2M) [application/zip]\n",
      "Saving to: ‘chromedriver-linux64.zip’\n",
      "\n",
      "chromedriver-linux6 100%[===================>]   8.20M  14.4MB/s    in 0.6s    \n",
      "\n",
      "2024-04-30 16:34:49 (14.4 MB/s) - ‘chromedriver-linux64.zip’ saved [8597995/8597995]\n",
      "\n",
      "Archive:  chromedriver-linux64.zip\n",
      "  inflating: chromedriver-linux64/LICENSE.chromedriver  \n",
      "  inflating: chromedriver-linux64/chromedriver  \n",
      "Collecting selenium\n",
      "  Downloading selenium-4.20.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting parsel\n",
      "  Downloading parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (2.31.0)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver_manager) (24.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
      "Collecting httpcore==1.* (from httpx)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cssselect>=1.2.0 (from parsel)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from parsel) (4.9.4)\n",
      "Collecting w3lib>=1.19.0 (from parsel)\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Installing collected packages: w3lib, python-dotenv, outcome, jmespath, h11, cssselect, wsproto, webdriver_manager, trio, parsel, httpcore, trio-websocket, httpx, selenium\n",
      "Successfully installed cssselect-1.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jmespath-1.0.1 outcome-1.3.0.post0 parsel-1.9.1 python-dotenv-1.0.1 selenium-4.20.0 trio-0.25.0 trio-websocket-0.11.1 w3lib-2.1.2 webdriver_manager-4.0.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Downloading Google Chrome\n",
    "!wget https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chrome-linux64.zip\n",
    "\n",
    "# Unzipping the binary file\n",
    "!unzip chrome-linux64.zip\n",
    "\n",
    "# Downloading latest Chromedriver\n",
    "!wget https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chromedriver-linux64.zip\n",
    "\n",
    "# Unzipping the binary file\n",
    "!unzip chromedriver-linux64.zip\n",
    "\n",
    "# Installing Selenium and webdriver_manager\n",
    "!python3 -m pip install selenium webdriver_manager httpx parsel jmespath pandas\n",
    "\n",
    "# Removing archive files\n",
    "!rm chrome-linux64.zip  chromedriver-linux64.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iYj1xqVXGIU"
   },
   "source": [
    "## Step 2: Import Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikCwz07BTtEM"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import selenium\n",
    "import json\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import time\n",
    "from parsel import Selector\n",
    "from typing import Dict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCfjikpsXJ7B"
   },
   "source": [
    "## Step 3: Configure Selenium WebDriver for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPY44XZUTvma"
   },
   "outputs": [],
   "source": [
    "## Setup chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\") # Ensure GUI is off\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--window-size=1600,900\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqpBR8PaU82s"
   },
   "outputs": [],
   "source": [
    "# Set path to chrome/chromedriver as per your configuration\n",
    "\n",
    "# Specify the paths for Chrome and ChromeDriver\n",
    "chrome_binary_path = \"/content/chrome-linux64/chrome\"\n",
    "chromedriver_path = \"/content/chromedriver-linux64/chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FS9_gqYU9sg"
   },
   "outputs": [],
   "source": [
    "# Initialize chrome_options and webdriver_service\n",
    "chrome_options.binary_location = chrome_binary_path\n",
    "webdriver_service = Service(chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3QhX7NEX3ih"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f15cc0YPX32O"
   },
   "source": [
    "## Step 4: Initialise the Google Chrome WebDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2O13NTVU2_S"
   },
   "outputs": [],
   "source": [
    "# Use the `webdriver_service` to initialise the webdriver.\n",
    "driver = webdriver.Chrome(service=webdriver_service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pXw1MAcX59x"
   },
   "source": [
    "## Step 5: Define Target URL (Make Sure to Verify the URL is Correct and Up-to-date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6qGGct_Tyj3"
   },
   "outputs": [],
   "source": [
    "# Set the URL to web scrape and store it in the `url` variable.\n",
    "url = \"https://www.aliexpress.com/category/44/consumer-electronics.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FT30lDkPT5Oe"
   },
   "outputs": [],
   "source": [
    "# Navigate to the URL webpage address that was stored in the `url` variable.\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the dynamic content to load.\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgozLge-YDC7"
   },
   "source": [
    "## Step 6: Identify and Extract Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSUtXVWjYGpA"
   },
   "outputs": [],
   "source": [
    "# Define the list to store the product data that will be extracted from the AliExpress Consumer ELectronics product category webpage into.\n",
    "products_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjhO8b6VXh0p"
   },
   "outputs": [],
   "source": [
    "# Define the `extract_search(response)` function.\n",
    "def extract_search(response) -> Dict:\n",
    "    \"\"\"extract json data from search page\"\"\"\n",
    "    sel = Selector(response.text)\n",
    "\n",
    "    # Find the script with result.pagectore data in it._it_t_=\n",
    "    script_with_data = sel.xpath('//script[contains(.,\"_init_data_=\")]')\n",
    "\n",
    "    # Select the page data from javascript variable in script tag using regex.\n",
    "    data = json.loads(script_with_data.re(r'_init_data_\\s*=\\s*{\\s*data:\\s*({.+}) }')[0])\n",
    "    return data['data']['root']['fields']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6xr12TKXVTS",
    "outputId": "77aedba2-d3c4-4b34-954c-a0d86c9cb4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                                url  \\\n",
      "0  3256806102778480  https://www.aliexpress.com/item/32568061027784...   \n",
      "1  3256805975404053  https://www.aliexpress.com/item/32568059754040...   \n",
      "2  3256805546949310  https://www.aliexpress.com/item/32568055469493...   \n",
      "3  3256806535734250  https://www.aliexpress.com/item/32568065357342...   \n",
      "4  3256804176518715  https://www.aliexpress.com/item/32568041765187...   \n",
      "\n",
      "      type                                              title   price  \\\n",
      "0  natural  X15 Wholesale Tws Earphone Bluetooth Wireless ...    4.86   \n",
      "1  natural  X15Pro TWS Wireless Bluetooth Earphones Stereo...    0.99   \n",
      "2  natural  E6S TWS Wireless Bluetooth Headset Waterproof ...    1.99   \n",
      "3  natural  Air Pro Bluetooth 5.0 Earphone Wireless Headph...    0.99   \n",
      "4       ad  LiFePO4 48V 150Ah 100Ah 200Ah Battery Pack 600...  666.86   \n",
      "\n",
      "  currency         trade                                          thumbnail  \\\n",
      "0      USD  10,000+ sold  ae01.alicdn.com/kf/S07988f3b83af4f77bcc48cc092...   \n",
      "1      USD  10,000+ sold  ae01.alicdn.com/kf/S6a2796b55c454e0a8f09faba40...   \n",
      "2      USD    3000+ sold  ae01.alicdn.com/kf/S7839654865d947eaa147e8431b...   \n",
      "3      USD     500+ sold  ae01.alicdn.com/kf/S219283cdda4149f398af930f94...   \n",
      "4      USD      128 sold  ae01.alicdn.com/kf/Sf72bd1fe062f4aeb81111948b4...   \n",
      "\n",
      "                               store_url            store_name    store_id  \\\n",
      "0  //www.aliexpress.com/store/1102818719       Yunzhiyao Store  1102818719   \n",
      "1  //www.aliexpress.com/store/1102818719       Yunzhiyao Store  1102818719   \n",
      "2  //www.aliexpress.com/store/1101356467     Shop5370096 Store  1101356467   \n",
      "3  //www.aliexpress.com/store/1102528368      NEX Global Store  1102528368   \n",
      "4  //www.aliexpress.com/store/1102129022  JOSMA Official Store  1102129022   \n",
      "\n",
      "   store_ali_id  \n",
      "0    2673456007  \n",
      "1    2673456007  \n",
      "2     239350035  \n",
      "3    2671922205  \n",
      "4    2667313793  \n"
     ]
    }
   ],
   "source": [
    "# Define the `parse_search` function to include \"store\" details.\n",
    "def parse_search(response):\n",
    "    \"\"\"Parse the search page response for product preview results\"\"\"\n",
    "    data = extract_search(response)  # Assuming you have a function called `extract_search`\n",
    "    parsed = []\n",
    "    for result in data[\"mods\"][\"itemList\"][\"content\"]:\n",
    "        store = result[\"store\"]\n",
    "        parsed.append({\n",
    "            \"id\": result[\"productId\"],\n",
    "            \"url\": f\"https://www.aliexpress.com/item/{result['productId']}.html\",\n",
    "            \"type\": result[\"productType\"],\n",
    "            \"title\": result[\"title\"][\"displayTitle\"],\n",
    "            \"price\": result[\"prices\"][\"salePrice\"][\"minPrice\"],\n",
    "            \"currency\": result[\"prices\"][\"salePrice\"][\"currencyCode\"],\n",
    "            \"trade\": result.get(\"trade\", {}).get(\"tradeDesc\"),\n",
    "            \"thumbnail\": result[\"image\"][\"imgUrl\"].lstrip(\"/\"),\n",
    "            \"store_url\": store[\"storeUrl\"],\n",
    "            \"store_name\": store[\"storeName\"],\n",
    "            \"store_id\": store[\"storeId\"],\n",
    "            \"store_ali_id\": store[\"aliMemberId\"],\n",
    "        })\n",
    "    return parsed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the total number of pages.\n",
    "    num_pages = 18\n",
    "\n",
    "    # Initialise an empty list, named ``all_product_data``, to store the product data.\n",
    "    all_product_data = []\n",
    "\n",
    "    # Loop through each page.\n",
    "    for page_num in range(1, num_pages + 1):\n",
    "        url = f\"https://www.aliexpress.com/category/44/consumer-electronics.html?page={page_num}\"\n",
    "        resp = httpx.get(url, follow_redirects=True)\n",
    "        product_data = parse_search(resp)\n",
    "        all_product_data.extend(product_data)\n",
    "\n",
    "    # Convert the combined data to the ``df_all_product_data`` DataFrame.\n",
    "    df_all_product_data = pd.json_normalize(all_product_data)\n",
    "\n",
    "    # Save the ``df_all_product_data`` DataFrame to a CSV file, named ``Resit_AliExpress_Consumer_Electronics_Product_Data``.\n",
    "    df_all_product_data.to_csv(\"Resit_AliExpress_Consumer_Electronics_Product_Data.csv\", index=False)\n",
    "\n",
    "    # Print the first few rows of the ``df_all_product_data`` DataFrame.\n",
    "    print(df_all_product_data.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
